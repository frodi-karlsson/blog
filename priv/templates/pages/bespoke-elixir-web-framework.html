---
title: Bespoke Elixir: Building a Lightweight Web Framework
date: 2026-02-25
category: Elixir
summary: A deep dive into the custom-built Elixir webserver powering this very page.
canonical: https://blog.frodikarlsson.com/bespoke-elixir-web-framework
---
<% layout.html %>
  <slot:title>Bespoke Elixir: Building a Lightweight Web Framework</slot:title>
  <slot:description>A deep dive into the custom-built Elixir webserver powering this very page.</slot:description>
  <slot:og_type>article</slot:og_type>
  <slot:body>
    <% blog_post.html %>
      <slot:category>Elixir</slot:category>
      <slot:date>Feb 25, 2026</slot:date>
      <slot:title>Bespoke Elixir: Building a Lightweight Web Framework</slot:title>
      <slot:content>
        <p>This blog isn't running on WordPress, Phoenix, or even a static site generator. It's running on a bespoke web framework I wrote in Elixir. I didn't want to pull in a massive framework just to serve some HTML, so I built exactly what I neededâ€”from scratch, minus the HTTP parsing.</p>

        <p>I'm primarily a Node developer, but I've been wanting to explore Elixir and the BEAM. This project was the perfect excuse to dive in and see how it handles the basics of the web.</p>

        <h2>Performance on a Budget</h2>
        <p>The entire application is hosted on the cheapest DigitalOcean droplet available for just <strong>$4 a month</strong>. Despite the minimal resources, it achieves near-perfect Lighthouse scores. The combination of Elixir's efficiency and a lack of client-side bloat makes it incredibly fast.</p>

        <figure>
          <img src="/static/img/web-vitals.png" alt="Web Vitals: Performance 98, Accessibility 100, Best Practices 96, SEO 100" />
          <figcaption>Lighthouse scores for this very page.</figcaption>
        </figure>

        <p>Lighthouse measures perceived performance from a single user's perspective. To see how it holds up under real load, I ran <code>wrk</code> against the live server with 100 concurrent connections over 30 seconds:</p>

        <pre><code>wrk -t4 -c100 -d30s http://&lt;server&gt;
Running 30s test
  4 threads and 100 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    54.53ms   34.46ms 368.18ms   93.11%
    Req/Sec   496.29    144.31   727.00     80.87%
  59130 requests in 30.11s, 148.65MB read
Requests/sec:   1963.99
Transfer/sec:      4.94MB</code></pre>

        <p>Nearly <strong>2,000 requests per second</strong> with an average latency under 55ms, on a $4 droplet. The standard deviation is low too, so the average isn't misleading.</p>

        <h2>Routing Requests</h2>
        <p>I used <a href="https://hexdocs.pm/plug/Plug.Router.html" target="_blank" rel="noopener noreferrer">Plug.Router</a> to handle the routing. It's a simple, declarative way to map paths to functions. Here's how the main router is structured:</p>

        <pre><code class="language-elixir">defmodule Webserver.Router do
  use Plug.Router
  # ... imports and aliases ...

  plug(Plug.RequestId)
  plug(Plug.Logger)
  plug(Plug.Static, at: "/static", from: {:webserver, "priv/static"})

  plug(:match)
  plug(:dispatch)

  get "/health" do: json(conn, 200, %{status: "ok"})
  get "/live-reload", to: Webserver.LiveReload
  forward "/admin", to: AdminRouter
  forward "/", to: Webserver.Server
end</code></pre>

        <h2>The Core Server Loop</h2>
        <p>The main logic for serving pages lives in <code>Webserver.Server</code>. It takes the request path, looks it up in the cache, and returns the parsed HTML. If the page doesn't exist, it handles the 404 gracefully.</p>

        <pre><code class="language-elixir">def call(conn, _opts) do
  path = request_path(conn)
  result = try_get_page(path)

  case result do
    {:ok, parsed} ->
      conn
      |> put_resp_content_type("text/html")
      |> send_resp(200, parsed)
    {:error, :not_found} ->
      # Render custom 404 page...
  end
end</code></pre>

        <h2>Caching with ETS</h2>
        <p>To keep things fast, I use <a href="https://hexdocs.pm/elixir/main/ets.html" target="_blank" rel="noopener noreferrer">ETS</a> (Erlang Term Storage) for caching <strong>fully rendered HTML</strong>. Multiple processes can read from the cache simultaneously without any locking, which is essential for high concurrency.</p>

        <pre><code class="language-elixir">def get_page(server, path) do
  table = table_for(server)

  case :ets.lookup(table, {:page, path}) do
    [{_, %PageEntry{} = entry}] ->
      handle_maybe_stale(table, server, path, entry)

    [] ->
      GenServer.call(server, {:fetch_and_cache, path})
  end
end</code></pre>

        <p>The <code>handle_maybe_stale</code> function implements a simple TTL-based revalidation strategy. It checks if a configurable interval has passed since the last check. If it has, the cache revalidates the entry based on the file's <code>mtime</code> on disk.</p>

        <h3>Stale-While-Revalidate (SWR)</h3>
        <p>The first version of this cache did the revalidation synchronously on the request path. That keeps correctness simple, but it also means every "stale" request gets serialized through a single GenServer and can block behind filesystem reads + parsing. Under enough traffic, that becomes tail latency (or timeouts) even though we already have perfectly good HTML sitting in ETS.</p>

        <p>The current approach is <strong>stale-while-revalidate</strong>: when a cached entry is due for a check, the server returns the cached HTML immediately and kicks off a background revalidation that updates ETS if the file changed.</p>

        <p><strong>Benefits:</strong> no request ever blocks on revalidation work, so latency is predictable and the cache stays responsive under load. It also naturally smooths out bursts because revalidation happens at most once per page per interval (deduped).</p>

        <p><strong>Trade-offs:</strong> the HTML can be briefly stale (bounded by the check interval) and background failures don't surface to the user directly. Instead, you monitor revalidation error counters and logs.</p>

        <h2>A Custom Templating Language</h2>
        <p>I wanted a component-like experience without a heavy build step. I wrote a small templating system that supports partials and named slots using recursive regex.</p>

        <pre><code class="language-html">&lt;% layout.html %&gt;
  &lt;slot:title&gt;My Page&lt;/slot:title&gt;
  &lt;slot:body&gt;
    &lt;% header.html %/&gt;
    &lt;p&gt;Content goes here.&lt;/p&gt;
  &lt;/slot:body&gt;
&lt;%/ layout.html %&gt;</code></pre>

        <p>The parser works by scanning for component tags. When it finds a tag like <code>&lt;% layout.html %&gt;</code>, it extracts the inner content and immediately runs itself on that content. This allows for arbitrary nesting: a layout can contain a blog post component, which itself contains other partials or slots.

        Once the inner content is fully resolved, the parser scans it for <code>&lt;slot:name&gt;</code> tags to build a map of content for the parent component. Finally, it loads the partial file (e.g., <code>layout.html</code>) and replaces its <code>{{name}}</code> placeholders with the resolved slot content. This 'depth-first' approach ensures that every component has access to its fully rendered children before it renders itself.</p>

        <h2>Live Reload</h2>
        <p>For a smooth development experience, I implemented live reloading. The server watches the filesystem using <a href="https://github.com/synrc/fs" target="_blank" rel="noopener noreferrer">fs</a>. The browser keeps an SSE connection open, and when a change is detected, the server sends a signal to reload the page or swap CSS in place.</p>

        <h2>Hosting and Deployment</h2>
        <p>Deployment fully automated with GitHub Actions and Docker. When I push to <code>main</code>, an image is built and pushed to GHCR. On the droplet, <a href="https://containrrr.dev/watchtower/" target="_blank" rel="noopener noreferrer">Watchtower</a> detects the new image and restarts the container within 30 seconds. No manual intervention required.</p>

        <p>After the first deploy I hit an annoying issue: the container would slowly degrade and eventually start returning internal 503s. The root cause turned out to be the Docker <code>HEALTHCHECK</code>. I originally used <code>./bin/webserver eval "IO.puts(:ok)"</code>, which spawns a separate BEAM instance every check. On a tiny droplet that can time out and create unnecessary pressure. The fix was to switch the healthcheck to a simple HTTP probe against <code>/health</code>.</p>

        <h2>Why Not Phoenix?</h2>
        <p>I've never actually used <a href="https://www.phoenixframework.org/" target="_blank" rel="noopener noreferrer">Phoenix</a>, but from what I've heard it's one of the best web frameworks out there, not just in Elixir. If I were starting a real project I'd probably reach for it.</p>

        <p>But I wanted to learn, not ship. I had just finished the <a href="https://hexdocs.pm/elixir/introduction-to-mix.html" target="_blank" rel="noopener noreferrer">Mix and OTP guide</a>, which builds up a TCP server from scratch. It's a long guide and covers a lot of ground. Jumping straight to Phoenix after that felt like skipping steps. Plug sits in between: it handles HTTP without making all the other decisions for you.</p>

        <p>Having to figure out caching, static files, and templates myself meant I actually understood what I was building. That's the point.</p>

        <h2>Elixir vs Node</h2>
        <p>Most of my professional work is in TypeScript and Node. They are great tools, but where they often struggle is concurrency. Node's single-threaded event loop requires workarounds for heavy lifting. In Elixir, concurrency is a first-class citizen.</p>

        <p>The Erlang VM (BEAM) is perfect for this kind of work. It doesn't have <a href="https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/" target="_blank" rel="noopener noreferrer">colored functions</a>. You don't think about async versus sync because the <a href="https://www.erlang.org/blog/a-brief-beam-primer/" target="_blank" rel="noopener noreferrer">BEAM</a> handles scheduling for you. Every request gets its own process, making it incredibly resilient and efficient. If a process crashes, the supervisor restarts it, and nothing else is affected.</p>

        <p>Building this bespoke framework over the last few days has been a great way to learn Elixir. It's a powerful, elegant language that makes building resilient systems feel natural. It's definitely a tool I'll be reaching for again.</p>

        <p>You can even <a href="https://github.com/frodi-karlsson/blog/blob/main/priv/templates/pages/bespoke-elixir-web-framework.html" target="_blank" rel="noopener noreferrer">view the source for this very page on GitHub</a> to see how the templating works in practice.</p>
      </slot:content>
    <%/ blog_post.html %>
  </slot:body>
<%/ layout.html %>
